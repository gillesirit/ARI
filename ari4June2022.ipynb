{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing ARS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 1: Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from math import *\n",
    "from random import randint\n",
    "# FOR PLOT\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# FOR CHI-SQUARE - MUTUAL INFORMATION - RELIEF\n",
    "import sklearn_relief as relief\n",
    "\n",
    "# FOR CROSS FOLD VALIDATION\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "# FOR TESTING ON LOGISTIC REGRESSION\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "# where all utilities are defined\n",
    "import utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 2: Defining binary functions in functions.py\n",
    "## ACTION 3: Dataset generation, pair generation and sampling in data_generation.py\n",
    "## ACTION 4: Defining utilities for chi2 and mutual information in ch2_mi.py\n",
    "## ACTION 5: Defining baseline logistic regression in baseline.py\n",
    "## ACTION 6: Defining ARS in ars.py\n",
    "## ACTION 7: Function to validate ARS stability wrt sample size - order relevanceÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_score_latex(dimension,row_name,list_of_score):\n",
    "    latex_line=\"\"\n",
    "    for i in range(dimension):\n",
    "        latex_line+=\" & \" +str(round(list_of_score[i],2))\n",
    "    print(row_name+latex_line+\"\\\\\\\\\")\n",
    "    return True\n",
    "\n",
    "def test_stability_ars(filename,number_of_test,sample_size_list):\n",
    "    dataset, X, y, dimension = load_dataset(filename)\n",
    "    dataset_size= dataset.shape[0]\n",
    "    positive= np.sum(dataset, axis = 0)[dimension]\n",
    "    print(\"****INFORMATION ON INITIAL DATA *******\")\n",
    "    print(\"dataset:\",filename,\"size\",dataset_size,\"dimension:\",dimension,\" - with\",positive,\"elements in class 1.\")\n",
    "    list_of_attributes=[]\n",
    "    for i in range(dimension):\n",
    "        list_of_attributes.append(i)\n",
    "    for sample_size in sample_size_list:\n",
    "        mean_ars_scores = [0]*dimension\n",
    "        for u in range(number_of_test):\n",
    "            sample_set = generate_sample_set(dataset,sample_size)\n",
    "            list_of_pairs = all_pairs(sample_set)\n",
    "            ars_scores = select_features_ars(dimension,list_of_attributes,sample_set,list_of_pairs)\n",
    "            for j in range(dimension):\n",
    "                mean_ars_scores[j]+=ars_scores[j]\n",
    "        mean_ars_scores    = [a*(1/number_of_test) for a in mean_ars_scores]\n",
    "        display_score_latex(dimension,str(sample_size),mean_ars_scores)\n",
    "    return True\n",
    "\n",
    "def test_stability_ars_new(f,dimension,number_of_test,sample_size_list):\n",
    "    list_of_attributes=[]\n",
    "    for i in range(dimension):\n",
    "        list_of_attributes.append(i)\n",
    "    for sample_size in sample_size_list:\n",
    "        mean_ars_scores = [0]*dimension\n",
    "        for u in range(number_of_test):\n",
    "            create_general_dataset(f,dimension,sample_size)\n",
    "            filename= \"datasets-tested/dataset_general.csv\"\n",
    "            dataset, X, y, dimension = load_dataset(filename)\n",
    "            #dataset_size= dataset.shape[0]\n",
    "            #positive= np.sum(dataset, axis = 0)[dimension]\n",
    "            #print(\"****INFORMATION ON INITIAL DATA *******\")\n",
    "            #print(\"dataset:\",filename,\"size\",dataset_size,\"dimension:\",dimension,\" - with\",positive,\"elements in class 1.\")\n",
    "            list_of_pairs = all_pairs(dataset)\n",
    "            ars_scores = select_features_ars(dimension,list_of_attributes,dataset,list_of_pairs)\n",
    "            for j in range(dimension):\n",
    "                mean_ars_scores[j]+=ars_scores[j]\n",
    "        mean_ars_scores = [a*(1/number_of_test) for a in mean_ars_scores]\n",
    "        display_score_latex(dimension,str(sample_size),mean_ars_scores)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 8: Validate ars stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=g1_array\n",
    "dimension=15\n",
    "#size=64\n",
    "#create_general_dataset(f,dimension,size)\n",
    "#create_csv_binary_dataset(f)\n",
    "filename=\"datasets-tested/dataset_binary.csv\"\n",
    "number_of_test = 10\n",
    "sample_size_list =[50,100,200,300,400]\n",
    "#test_stability_ars(filename,number_of_test,sample_size_list)\n",
    "test_stability_ars_new(f,dimension,number_of_test,sample_size_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 9: Function to compare ARS - chi-square - mutual information - relief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_score_on_dataset(filename,number_of_test,sample_ratio):\n",
    "    dataset, X, y, dimension = load_dataset(filename)\n",
    "    #INFO\n",
    "    dataset_size=dataset.shape[0]\n",
    "    print(\"****INFORMATION ON INITIAL DATA *******\")\n",
    "    print(\"dataset:\",filename,\"size:\",dataset_size,\"dimension:\",dimension)\n",
    "\n",
    "    #create A : list of attribute as index 0, 1, ...\n",
    "    list_of_attributes=[]\n",
    "    attribute_names=[]\n",
    "    for i in range(dimension):\n",
    "        list_of_attributes.append(i)\n",
    "        attribute_names.append(\"a\"+str(i+1))\n",
    "    #print(attribute_names)\n",
    "    \n",
    "    sample_size = int(dataset_size*sample_ratio)\n",
    "    mean_ars_scores    = [0]*dimension\n",
    "    mean_chi_scores    = [0]*dimension\n",
    "    mean_mut_scores    = [0]*dimension\n",
    "    mean_relief_scores = [0]*dimension\n",
    "    print(sample_size)\n",
    "\n",
    "    for u in range(number_of_test):\n",
    "        sample_set = generate_sample_set(dataset,sample_size)\n",
    "        list_of_pairs = all_pairs(sample_set)\n",
    "        ars_scores = select_features_ars(dimension,list_of_attributes,sample_set,list_of_pairs)\n",
    "# NOT SURE WE TEST ON THE SAME SET BECAUSE OF TEST_SIZE PARAM IN PREPARE\n",
    "        X_train_enc, y_train_enc, X_test_enc=prepare_all(X, y, test_size=sample_ratio, random_state=1)\n",
    "        X_train_chi, X_test_chi, fs_chi = select_all_features_chi2(X_train_enc, y_train_enc, X_test_enc)\n",
    "        X_train_mut, X_test_mut, fs_mut = select_all_features_mutual(X_train_enc, y_train_enc, X_test_enc)\n",
    "    \n",
    "    # RELIEF\n",
    "        relief_scores = relief.Relief(n_features=dimension) # we check all attributes\n",
    "        my_transformed_matrix = relief_scores.fit_transform(X_train_enc,y_train_enc)\n",
    "\n",
    "# NORMALIZATION FACTORS - All scores are normalized\n",
    "        Z_ars,Z_chi,Z_mi,Z_relief=0,0,0,0\n",
    "        for i in range(dimension):\n",
    "            Z_ars    += ars_scores[i]\n",
    "            Z_chi    += fs_chi.scores_[i]\n",
    "            Z_mi     += fs_mut.scores_[i]\n",
    "            Z_relief += relief_scores.w_[i]\n",
    "#UPDATE MEAN SCORES BY ADDING NORMALIZED SCORES IN [0,1]  +0.01 to avoid division by 0\n",
    "        for j in range(dimension):\n",
    "            mean_ars_scores[j]   += ars_scores[j]/(Z_ars + 0.01)\n",
    "            mean_chi_scores[j]   += fs_chi.scores_[j]/(Z_chi + 0.01)\n",
    "            mean_mut_scores[j]   += fs_mut.scores_[j]/(Z_mi + 0.01)\n",
    "            mean_relief_scores[j]+= relief_scores.w_[j]/(Z_relief + 0.01)\n",
    "\n",
    "    mean_ars_scores    = [a*(1/number_of_test) for a in mean_ars_scores]\n",
    "    mean_chi_scores    = [a*(1/number_of_test) for a in mean_chi_scores]\n",
    "    mean_mut_scores    = [a*(1/number_of_test) for a in mean_mut_scores]\n",
    "    mean_relief_scores = [a*(1/number_of_test) for a in mean_relief_scores]\n",
    "\n",
    "    pyplot.title(\"ARS\")\n",
    "    pyplot.bar(attribute_names, mean_ars_scores)\n",
    "    pyplot.show()\n",
    "\n",
    "    pyplot.title(\"CHI-SQUARE\")\n",
    "    pyplot.bar(attribute_names, mean_chi_scores)\n",
    "    pyplot.show()\n",
    "\n",
    "    pyplot.title(\"MUTUAL INFORMATION\")\n",
    "    pyplot.bar(attribute_names, mean_mut_scores)\n",
    "    pyplot.show()\n",
    "\n",
    "    pyplot.title(\"RELIEF\")\n",
    "    pyplot.bar(attribute_names, mean_relief_scores)\n",
    "    pyplot.show()\n",
    "# PREPARE FOR LATEX\n",
    "    display_score_latex(dimension,\"   ars\",mean_ars_scores)\n",
    "    display_score_latex(dimension,\"  chi2\",mean_chi_scores)\n",
    "    display_score_latex(dimension,\"    mi\",mean_mut_scores)\n",
    "    display_score_latex(dimension,\"relief\",mean_relief_scores)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 10: Comparing score methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"datasets-tested/primary-tumor.data-no_missing.csv\"\n",
    "filename=\"datasets-tested/1-monks-1.csv\"\n",
    "#filename=\"datasets-tested/dataset_general.csv\"\n",
    "number_of_test = 2\n",
    "sample_ratio   = 0.33\n",
    "compare_score_on_dataset(filename,number_of_test,sample_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACTION 11: Comparing feature relevance score effectiveness on logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_binary_dataset(filename,k): #comparing accuracies by running logistic regression on k best features\n",
    "    dataset, X, y, dimension = load_dataset(filename)\n",
    "    print(\"data shape:\",X.shape, \"dimension\", dimension,\"nb of best features:\",k)\n",
    "    FOLDS=2\n",
    "    list_of_attributes=[]\n",
    "    for i in range(dimension):\n",
    "        list_of_attributes.append(i)\n",
    "    acc_baseline_all_features=baseline_for_binary_with_all(X, y,FOLDS) #10 fold cross valid\n",
    "    list_of_accuracy_ars=[]\n",
    "    list_of_accuracy_chi2=[]\n",
    "    list_of_accuracy_mi=[]\n",
    "    list_of_accuracy_relief=[]\n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True)\n",
    "    for train, test in skf.split(X,y):\n",
    "        #print(\"****************\")\n",
    "        X_train_chi2, X_test_chi2, _ = select_k_features_chi2(X[train], y[train], X[test], k)\n",
    "        X_train_mi, X_test_mi, _ = select_k_features_mi(X[train], y[train], X[test], k)\n",
    "        r = relief.Relief(n_features=k)\n",
    "        X_train_relief = r.fit_transform(X[train], y[train])\n",
    "        X_test_relief = r.fit_transform(X[test], y[test])              \n",
    "    # ARS feature selection\n",
    "        #create A : list of attribute as index 0, 1, ...\n",
    "        list_of_attributes=[]\n",
    "        for i in range(dimension):\n",
    "            list_of_attributes.append(i)\n",
    "        sample_set = dataset[train]\n",
    "        list_of_pairs = all_pairs(sample_set)\n",
    "        ars_scores = select_features_ars(dimension,list_of_attributes,sample_set,list_of_pairs)\n",
    "        s = numpy.array(ars_scores)\n",
    "        sort_index = np.argsort(s)\n",
    "        print(sort_index)\n",
    "        print(ars_scores)\n",
    "        #transform the dataset to keep only the k relevant features\n",
    "        \n",
    "        a=accuracy(X_train_ars,y[train],X_test_ars,y[test])\n",
    "        list_of_accuracy_ars.append(a)   \n",
    "    # CHI2\n",
    "        a=accuracy(X_train_chi2,y[train],X_test_chi2,y[test])\n",
    "        list_of_accuracy_chi2.append(a)\n",
    "        #print(\"  chi2\",a)   \n",
    "    # MI \n",
    "        a=accuracy(X_train_mi,y[train],X_test_mi,y[test])\n",
    "        list_of_accuracy_mi.append(a)\n",
    "        #print(\"    mi\",a)\n",
    "    # RELIEF\n",
    "        a=accuracy(X_train_relief,y[train],X_test_relief,y[test])\n",
    "        list_of_accuracy_relief.append(a)\n",
    "        #print(\"relief\",a)\n",
    "        \n",
    "    acc_ars   = mean(list_of_accuracy_ars)\n",
    "    acc_chi2  = mean(list_of_accuracy_chi2)\n",
    "    acc_mi    = mean(list_of_accuracy_mi)\n",
    "    acc_relief= mean(list_of_accuracy_relief)\n",
    "    return(acc_baseline_all_features,acc_ars,acc_chi2,acc_mi,acc_relief)\n",
    "    \n",
    "def test_categorical_dataset(filename,k):  \n",
    "    dataset, X, y, dimension = load_dataset(filename)\n",
    "    print(\"data shape:\",X.shape, \"dimension\", dimension,\"nb of used best features:\",k)\n",
    "    FOLDS=10\n",
    "    list_of_attributes=[]\n",
    "    for i in range(dimension):\n",
    "        list_of_attributes.append(i)\n",
    "    acc_baseline_all_features=baseline_for_categorical_with_all(X,y,FOLDS) #10 fold cross valid\n",
    "    list_of_accuracy_ars=[]\n",
    "    list_of_accuracy_chi2=[]\n",
    "    list_of_accuracy_mi=[]\n",
    "    list_of_accuracy_relief=[]\n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True)\n",
    "    X_enc=prepare_input(X)\n",
    "    y_enc=prepare_target(y)\n",
    "    for train, test in skf.split(X,y):\n",
    "        X_train_chi2_enc, X_test_chi2_enc, _ = select_k_features_chi2(X_enc[train], y_enc[train], X_enc[test], k)\n",
    "        X_train_mi_enc, X_test_mi_enc, _ = select_k_features_mi(X_enc[train], y_enc[train], X_enc[test], k)\n",
    "        r = relief.Relief(n_features=k)\n",
    "        X_train_relief_enc = r.fit_transform(X_enc[train], y_enc[train])\n",
    "        X_test_relief_enc = r.fit_transform(X_enc[test], y_enc[test])\n",
    "    # ARS feature selection\n",
    "        #create A : list of attribute as index 0, 1, ...\n",
    "        list_of_attributes=[]\n",
    "        for i in range(dimension):\n",
    "            list_of_attributes.append(i)\n",
    "        sample_set = dataset[train]\n",
    "        list_of_pairs = all_pairs(sample_set)\n",
    "        ars_scores = select_features_ars(dimension,list_of_attributes,sample_set,list_of_pairs)\n",
    "        s = np.array(ars_scores)\n",
    "        sort_index = np.argsort(s)\n",
    "        sort_index=np.flipud(sort_index)\n",
    "        #print(\"ars index\",sort_index)\n",
    "        #print(\"ars scores:\",ars_scores)\n",
    "        # transform the dataset to keep only the k relevant features\n",
    "        X_train_ars_enc = np.delete(X_enc[train], sort_index[0:k],axis=1)\n",
    "        X_test_ars_enc  = np.delete(X_enc[test],sort_index[0:k],axis=1)\n",
    "        a=accuracy(X_train_ars_enc,y[train],X_test_ars_enc,y[test])\n",
    "        list_of_accuracy_ars.append(a)  \n",
    "    # CHI2 feature selection\n",
    "        a=accuracy(X_train_chi2_enc,y_enc[train],X_test_chi2_enc,y_enc[test])\n",
    "        list_of_accuracy_chi2.append(a)\n",
    "    # MI feature selection\n",
    "        a=accuracy(X_train_mi_enc,y_enc[train],X_test_mi_enc,y_enc[test])\n",
    "        list_of_accuracy_mi.append(a)\n",
    "    # RELIEF\n",
    "        a=accuracy(X_train_relief_enc,y_enc[train],X_test_relief_enc,y_enc[test])\n",
    "        list_of_accuracy_relief.append(a)\n",
    "        \n",
    "    acc_ars   = mean(list_of_accuracy_ars)\n",
    "    acc_chi2  = mean(list_of_accuracy_chi2)\n",
    "    acc_mi    = mean(list_of_accuracy_mi)\n",
    "    acc_relief= mean(list_of_accuracy_relief)\n",
    "    return(acc_baseline_all_features,acc_ars,acc_chi2,acc_mi,acc_relief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"datasets-tested/\"\n",
    "file_to_be_tested=os.listdir(data_path)\n",
    "file_to_be_tested=[\"arcene_train.data.csv\"]\n",
    "for filename in file_to_be_tested:\n",
    "    dataset = read_csv(data_path+filename, header=None)\n",
    "    data = dataset.values\n",
    "    dimension=data.shape[1] - 1\n",
    "    \n",
    "    k_list= [dimension//5, dimension//4,dimension//3, dimension//2, dimension-1]\n",
    "    k_list=list(set(k_list))\n",
    "    print(\"Tested dataset:\",filename,\"- dimension:\",dimension,\" - k best dimension tested:\",k_list)\n",
    "    for num in k_list:\n",
    "        if num>=1:\n",
    "         acc_baseline_all_features,acc_ars,acc_chi2,acc_mi,acc_relief=test_categorical_dataset(data_path+filename,num)\n",
    "         print(\"all:\",acc_baseline_all_features,\" - ars:\",acc_ars,\" - chi2:\",acc_chi2,\" - mi:\",acc_mi,\" - relief:\",acc_relief)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
